<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="K-planes. Factorization of 4D volumes">
    <meta name="author" content="Giacomo Meanti*,
                                Sara Fridovich-Keil*,
                                Frederik Warburg,
                                Ben Recht,
                                Angjoo Kanazawa">


    <title>K-Plane</title>

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <link rel="icon" href="assets/logo.png" type="image/png">
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
</head>

<body>
<header>
    <div class="text-center">
        <div class="container"></div>
        <div class="row mb-2 mt-4" id="paper-title">
            <h1 class="col-md-12 text-center">
                K-Planes
            </h1>
            <h3 class="col-md-12 text-center">
                Explicit Radiance Fields in Space, Time, and Appearance
            </h3>
            <h3 class="col-md-12 text-center">
                <small>CVPR 2023</small>
            </h3>
        </div>
        <hr>
        <p class="authors">
            <a href="https://people.eecs.berkeley.edu/~sfk/">Sara Fridovich-Keil*</a>,
            <a href="https://www.iit.it/web/iit-mit-usa/people-details/-/people/giacomo-meanti">Giacomo Meanti*</a>,
            <a href="https://frederikwarburg.github.io/">Frederik Rahb√¶k Warburg</a>,
            <a href="https://people.eecs.berkeley.edu/~brecht/">Benjamin Recht</a>,
            <a href="https://people.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa</a>
        </p>

        <div class="nerf_equal">
            <p> * Denotes Equal Contribution </p>
        </div>

        <br>
        <div class="row caption-row">
            <div class="col padding-0">
                <img src="assets/paper_thumbnail.jpg" width="80">
            </div>
            <div class="col padding-0">
                <img src="https://logos-download.com/wp-content/uploads/2016/09/GitHub_logo.png" width="80">
            </div>
            <div class="col padding-0">
                <img src="assets/nerfacc.png" width="100">
            </div>
            <div class="col padding-0">
                <img src="assets/dozer.png" width="120">
            </div>
        </div>
        <div class="row caption-row">
            <div class="col padding-0">
                <a class="btn btn-primary" href="https://arxiv.org/abs/2301.10241">Paper</a>
            </div>
            <div class="col padding-0">
                <a class="btn btn-primary" href="https://github.com/sarafridov/K-Plane">Code</a>
            </div>
            <div class="col padding-0">
                <a class="btn btn-primary" href="https://www.nerfacc.com/en/stable/examples/dynamic/kplanes.html">NerfAcc integration</a>
            </div>
            <div class="col padding-0">
                <a class="btn btn-primary" img src="assets/dozer.png" href="https://github.com/Giodiro/kplanes_nerfstudio">NerfStudio integration</a>
            </div>
        </div>
        <!-- <div class="btn-group" role="group" aria-label="Top menu">
            <div><img src="assets/paper_thumbnail.jpg" width="80"><br><a class="btn btn-primary" href="https://arxiv.org/abs/2301.10241">Paper</a></div>
            <div><img src="https://logos-download.com/wp-content/uploads/2016/09/GitHub_logo.png" width="80"><br><a class="btn btn-primary" href="https://github.com/sarafridov/K-Plane">Code</a></div>
            <div><img src="assets/nerfacc.png" width="80"><br><a class="btn btn-primary" href="https://www.nerfacc.com/en/stable/examples/dynamic/kplanes.html">NerfAcc integration</a></div>
            <div><img src="assets/dozer.png" width="80"><br><a class="btn btn-primary" img src="assets/dozer.png" href="https://github.com/Giodiro/kplanes_nerfstudio">NerfStudio integration</a></div>
        </div> -->
    </div>
</header>


<div class="container">
    <section id="teaser-videos">
        <div class="row caption-row">
            <div class="col padding-0">
                <p class="caption_bold">3D  <br> Static Scene</p>
            </div>
            <div class="col padding-0">
                <p class="caption_bold">4D Mono-"Teleporting" Dynamic Scene</p>
            </div>
            <div class="col padding-0">
                <p class="caption_bold">4D Multiview <br> Dynamic Scene</p>
            </div>
            <div class="col padding-0">
                <p class="caption_bold">3D Varying <br> Appearance Scene</p>
            </div>
        </div>
        <figure>
            <div class="row video-row">
                <video class="results_video" autoplay muted loop playsinline>
                    <source src="assets/small_teaser.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </figure>
            <p class="caption_justify">
                <b>Planar factorization of d-dimensional spaces.</b> We propose a simple planar factorization for radiance fields that naturally extends to arbitrary-dimensional spaces, and that scales gracefully with dimension in both optimization time and model size. We show the advantages of our approach on 3D static volumes, 3D photo collections with varying appearances, and 4D dynamic videos.
            </p>
    </section>

    <section id="abstract">
        <h2>Abstract</h2>
        <hr>
        <figure>
            <img src="assets/intro_figure.jpg" alt="Diagram describing the K-Planes model.">
        </figure>
        <p class="caption_justify">
            <b> Abstract: </b> We introduce k-planes, a white-box model for radiance fields in arbitrary dimensions. Our model
            uses  <i>d</i>-<i>choose</i>-<i>2</i> planes to represent a d-dimensional scene, providing a seamless way to go from static
            (d=3) to dynamic (d=4) scenes. This planar factorization makes adding dimension-specific priors easy, e.g. temporal smoothness and multi-resolution
            spatial structure, and induces a natural decomposition of static and dynamic components of a scene.
            We use a linear feature decoder with a learned color basis that yields similar performance as a nonlinear black-box MLP decoder.
            Across a range of synthetic and real, static and dynamic, fixed and varying appearance scenes, k-planes yields competitive and often state-of-the-art reconstruction fidelity with low memory usage,
            achieving 1000x compression over a full 4D grid, and fast optimization with a pure PyTorch implementation.
        </p>
    </section>

    <section id="method">
        <h2>K-Plane Factorization of 4D Dynamic Volumes</h2>
        <hr>
        <figure>
            <img src="assets/methods_ss.jpg" alt="Diagram describing the pipeline for K-Planes.">
        </figure>
        <p class="caption_justify">
            <b>Method overview.</b> (a) The k-plane representation decomposes 4D spatiotemporal volumes into six planes, three for space and three for spatiotemporal variations. To obtain the value of a 4D point \(\textbf{q}=(x,y,z,t)\), we first project the point into each plane (b) in which we do multiscale bilinear interpolation. (c) The interpolated values are multiplied and concatenated over \(S\) scales. (d) These features are decoded either with a small MLP or our explicit linear decoder. (e) We follow the standard volumetric rendering formula to predict color and density. The model is optimized by (f) minimizing the reconstruction loss with simple regularization in space and time.
        </p>
    </section>

    <section id="results">
        <h2>4D Dynamic Multiview Scenes</h2>
        <hr>
        <figure>
            <div class="row video-row">
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dynerf/small_salmon_path_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(a) Hybrid model</p>
                </div>
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dynerf/small_salmon_path_linear.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(b) Explicit model</p>
                </div>
            </div>
        </figure>
        <p class="caption_justify"> <b>Novel view synthesis for 4D dynamic volumes.</b> Both our explicit and hybrid models yield state-of-the-art reconstructions on real multi-view dynamic scenes.</p>
    </section>

    <section id="results2">
        <h2>Space-time Decomposition</h2>
        <hr>

        <!-- DyNeRF Space-time decomposition -->
        <div class="row caption-row">
            <div class="col padding-0">
                <p class="caption_bold">Full</p>
            </div>
            <div class="col padding-0">
                <p class="caption_bold">Space-only</p>
            </div>
            <div class="col padding-0">
                <p class="caption_bold">Time-only</p>
            </div>
        </div>
        <figure>
            <div class="row video-row">
                <video class="results_video" autoplay muted loop playsinline>
                    <source src="assets/dynerf/small_salmon_spacetime_mlp.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
            <div class="row video-row">
                <video class="results_video" autoplay muted loop playsinline>
                    <source src="assets/dynerf/small_cutbeef_spacetime_mlp.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </figure>
        <p class="caption_justify"><b>Space-time decomposition.</b> K-planes naturally decomposes a 4D video into static and dynamic components.
            We render the static part by setting the time planes to the identity, and the remainder is the dynamic part. This makes adding dimension-specific priors easy.</p>
    </section>

    <section id="results3">
        <h2>4D Dynamic Monocular "Teleporting-Camera" videos</h2>
        <hr>
        <!-- DNeRF MLP vs. Linear -->
        <figure>
            <div class="row video-row" style="margin: 0 16.66%;">
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dnerf/small_jumpingjacks_path_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(a) Hybrid model</p>
                </div>
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dnerf/small_jumpingjacks_path_linear.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(b) Explicit model</p>
                </div>
            </div>
        </figure>
        <p class="caption_justify"> <b>Novel view synthesis for 4D dynamic volumes.</b>
            Reconstruction and novel view generation on a monocular teleporting-camera dataset of dynamic synthetic objects (the D-NeRF dataset). D-NeRF training data includes a single view per timestep, but the camera can ‚Äúteleport‚Äù between adjacent timesteps. See <a href="https://hangg7.com/dycheck/">"Monocular Dynamic View Synthesis: A Reality Check"</a>.
        </p>
    </section>

    <section id="results4">
        <h2>Space-time Decomposition</h2>
        <hr>
        <!-- DNeRF Space-time decomposition -->
        <div style="margin-left: 18%; margin-right: 18%">
            <div class="row caption-row">
                <div class="col padding-0">
                    <p class="caption_bold">Full</p>
                </div>
                <div class="col padding-0">
                    <p class="caption_bold">Space-only</p>
                </div>
                <div class="col padding-0">
                    <p class="caption_bold">Time-only</p>
                </div>
            </div>
            <figure>
                <div class="row video-row">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dnerf/small_bouncingballs_spacetime_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="row video-row">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/dnerf/small_lego_spacetime_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
            </figure>
        </div>
       <p class="caption_justify">
           <b>Space-time decomposition.</b> K-planes naturally decomposes a 4D video into static and dynamic components.
           We render the static part by setting the time planes to the identity, and the remainder is the dynamic part. This makes adding dimension-specific priors easy.
       </p>
    </section>

    <section id="results5">
        <h2>In the wild capture: Varying appearance</h2>
        <hr>
        <figure>
            <div class="row video-row" style="margin: 0 25%;">
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_sacre_rendering_path.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_trevi_rendering_path.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_brandenburg_rendering_path.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(a) Hybrid model</p>
                </div>
                <div class="col-sm padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_sacre_rendering_path_linear.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_trevi_rendering_path_linear.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/nerfw/small_brandenburg_rendering_path_linear.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption_bold">(b) Explicit model</p>
                </div>
            </div>
        </figure>
        <p class="caption_justify">
          <b>Varying Appearance Phototourism Scenes. </b> Like NeRF-W, we can
interpolate our appearance code in either our explicit or hybrid model to alter the visual appearance of
landmarks, such as changing time of day. Appearance codes affect color but not geometry; note that objects in the foreground appear and disappear as the camera moves past them.
        </p>
    </section>

    <section id="results6">
        <h2>3D Static Forward Facing Scenes</h2>
        <hr>

        <figure>
            <div class="row video-row">
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_room_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_fern_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_leaves_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_fortress_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
            </div>
            <div class="row video-row">
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_orchids_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_flower_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_trex_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/llff/small_horns_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
            </div>
        </figure>
        <p class="caption_justify">
            <b> Static forward facing scenes.</b> Reconstruction and novel view generation on a dataset of forward facing captures (the LLFF dataset).
        </p>
    </section>

    <section id="results7">
        <h2>3D Synthetic Static Scenes</h2>
        <hr>
        <figure>
            <div class="row video-row">
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_ship_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_chair_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_drums_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_ficus_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
            </div>
            <div class="row video-row">
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_hotdog_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_lego_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_materials_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="col-6 col-md-3 padding-0">
                    <video class="results_video" autoplay muted loop playsinline>
                        <source src="assets/synth360/small_mic_mlp.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
            </div>
        </figure>
        <p class="caption_justify">
            <b> Static 360 scenes.</b> Reconstruction and novel view generation on a dataset of synthetic objects (the NeRF dataset).
        </p>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="row">
            <div class="col-sm-5" >
                <a href="https://arxiv.org/abs/2301.10241"><img class="screenshot" src="assets/paper_thumbnail.jpg" alt="thumbnail image of the paper"></a>
            </div>
            <div class="col-sm-7">
                <p><b>K-Planes: Explicit Radiance Fields in Space, Time, and Appearance</b></p>
                <p>Sara Fridovich-Keil*, Giacomo Meanti*, Frederik Rahb√¶k Warburg, Benjamin Recht, and Angjoo Kanazawa</p>

                <!-- <div><span class="material-icons"> description </span><a href=""> Paper preprint (PDF)</a></div> -->
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/abs/2301.10241"> arXiv</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/kplanes_bibtex.bib" type="text"> BibTeX</a></div>
                <div><span class="material-icons"> integration_instructions </span><a href="https://github.com/sarafridov/K-Planes"> Code</a></div>
            </div>
        </div>
        <p> The day before our arxiv release, a similar paper Hexplanes was released on arxiv. Please consider checking out that paper as well: <a href="https://caoang327.github.io/HexPlane"> https://caoang327.github.io/HexPlane/ </a> </p>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>
@inproceedings{kplanes_2023,
    title={K-Planes: Explicit Radiance Fields in Space, Time, and Appearance},
    author={Sara Fridovich-Keil and Giacomo Meanti and Frederik Rahb√¶k Warburg and Benjamin Recht and Angjoo Kanazawa},
    year={2023},
    booktitle={CVPR},
}
</code></pre>

    </section>

    <section id="acknowledgements">
        <h2>Acknowledgments</h2>
        <hr>
        <div>
            <p>
            Many thanks to <a href="https://www.matthewtancik.com">Matthew Tancik</a> and <a href="https://www.liruilong.cn/">Ruilong Li</a>, and other members of KAIR for helpful discussion and pointers to resources. We also thank the DyNeRF authors for their response to our questions about their method. We also thank <a href="https://joeylitalien.github.io/">Joey Litalien</a> for providing us with the framework for this website.
            <br/>
            <br/>
            <em>Detailed Drum Set</em> &copy;bryanajones (<a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a>)
            <br/>
            <em>Lego 856 Bulldozer</em> &copy;H√•vard Dalen (<a href="https://creativecommons.org/licenses/by-nc/2.0/">CC BY-NC 2.0</a>)
            <br/>
            <em>D-NeRF dataset</em> &copy;Alberto Pumarola
            <br/>
            <em>DyNeRF dataset</em> (<a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>)
            <br/>
            <em>Phototourism dataset</em> (<a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a>)
            </p>
        </div>
    </section>

    <footer>
        <p>This website is partially borrowed from <a href="https://nvlabs.github.io/instant-ngp">instant-NGP</a>.
    </footer>
</div>


</body>
</html>
